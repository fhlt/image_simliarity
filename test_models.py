#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test script for model integration
æ¨¡å‹é›†æˆæµ‹è¯•è„šæœ¬
"""

import os
import sys
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import get_clip_config, get_blip_config, get_model_config
from models import CLIPSimilarityEvaluator, BLIPSimilarityEvaluator

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_config_system():
    """æµ‹è¯•é…ç½®ç³»ç»Ÿ"""
    print("=== æµ‹è¯•é…ç½®ç³»ç»Ÿ ===")
    
    try:
        # æµ‹è¯•CLIPé…ç½®
        clip_config = get_clip_config()
        print(f"âœ“ CLIPé…ç½®: {clip_config.model.name} - {clip_config.model.model_name}")
        
        # æµ‹è¯•BLIPé…ç½®
        blip_config = get_blip_config()
        print(f"âœ“ BLIPé…ç½®: {blip_config.model.name} - {blip_config.model.model_name}")
        
        # æµ‹è¯•æ¨¡å‹é€‰æ‹©
        config1 = get_model_config("CLIP")
        config2 = get_model_config("BLIP")
        config3 = get_model_config("UNKNOWN")
        
        print(f"âœ“ æ¨¡å‹é€‰æ‹©æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— é…ç½®ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_model_imports():
    """æµ‹è¯•æ¨¡å‹å¯¼å…¥"""
    print("\n=== æµ‹è¯•æ¨¡å‹å¯¼å…¥ ===")
    
    try:
        from models import CLIPSimilarityEvaluator, BLIPSimilarityEvaluator, BaseSimilarityEvaluator
        print("âœ“ æ¨¡å‹å¯¼å…¥æˆåŠŸ")
        
        # æ£€æŸ¥ç±»æ˜¯å¦å­˜åœ¨
        assert hasattr(CLIPSimilarityEvaluator, 'compute_similarity')
        assert hasattr(BLIPSimilarityEvaluator, 'compute_similarity')
        assert hasattr(BaseSimilarityEvaluator, 'evaluate_dataset')
        
        print("âœ“ æ¨¡å‹ç±»æ–¹æ³•æ£€æŸ¥é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»ºï¼ˆä¸åŠ è½½å®é™…æ¨¡å‹ï¼‰"""
    print("\n=== æµ‹è¯•æ¨¡å‹åˆ›å»º ===")
    
    try:
        # æµ‹è¯•CLIPè¯„ä¼°å™¨åˆ›å»ºï¼ˆä½¿ç”¨CPUæ¨¡å¼é¿å…GPUä¾èµ–ï¼‰
        clip_evaluator = CLIPSimilarityEvaluator(
            model_name="openai/clip-vit-base-patch32",
            device="cpu",
            batch_size=4,
            image_size=224
        )
        print("âœ“ CLIPè¯„ä¼°å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•BLIPè¯„ä¼°å™¨åˆ›å»ºï¼ˆä½¿ç”¨CPUæ¨¡å¼é¿å…GPUä¾èµ–ï¼‰
        blip_evaluator = BLIPSimilarityEvaluator(
            model_name="Salesforce/blip-itm-base-coco",
            device="cpu",
            batch_size=4,
            image_size=384
        )
        print("âœ“ BLIPè¯„ä¼°å™¨åˆ›å»ºæˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹åˆ›å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_main_arguments():
    """æµ‹è¯•ä¸»ç¨‹åºå‚æ•°è§£æ"""
    print("\n=== æµ‹è¯•ä¸»ç¨‹åºå‚æ•° ===")
    
    try:
        import subprocess
        
        # æµ‹è¯•å¸®åŠ©ä¿¡æ¯
        result = subprocess.run([sys.executable, "main.py", "--help"], 
                              capture_output=True, text=True)
        if "CLIP" in result.stdout and "BLIP" in result.stdout:
            print("âœ“ å¸®åŠ©ä¿¡æ¯åŒ…å«æ¨¡å‹é€‰æ‹©")
        else:
            print("âœ— å¸®åŠ©ä¿¡æ¯ç¼ºå°‘æ¨¡å‹é€‰æ‹©")
            return False
        
        # æµ‹è¯•åˆ—å‡ºæ¨¡å‹
        result = subprocess.run([sys.executable, "main.py", "--list-models"], 
                              capture_output=True, text=True)
        if "CLIP" in result.stdout and "BLIP" in result.stdout:
            print("âœ“ æ¨¡å‹åˆ—è¡¨æ˜¾ç¤ºæ­£å¸¸")
        else:
            print("âœ— æ¨¡å‹åˆ—è¡¨æ˜¾ç¤ºå¼‚å¸¸")
            return False
        
        return True
        
    except Exception as e:
        print(f"âœ— ä¸»ç¨‹åºå‚æ•°æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_model_comparison():
    """æµ‹è¯•æ¨¡å‹æ¯”è¾ƒåŠŸèƒ½"""
    print("\n=== æµ‹è¯•æ¨¡å‹æ¯”è¾ƒ ===")
    
    try:
        # åˆ›å»ºä¸¤ä¸ªé…ç½®è¿›è¡Œæ¯”è¾ƒ
        clip_config = get_clip_config()
        blip_config = get_blip_config()
        
        print(f"CLIPé…ç½®:")
        print(f"  æ¨¡å‹åç§°: {clip_config.model.name}")
        print(f"  æ¨¡å‹æ–‡ä»¶: {clip_config.model.model_name}")
        print(f"  å›¾åƒå°ºå¯¸: {clip_config.model.image_size}")
        
        print(f"BLIPé…ç½®:")
        print(f"  æ¨¡å‹åç§°: {blip_config.model.name}")
        print(f"  æ¨¡å‹æ–‡ä»¶: {blip_config.model.model_name}")
        print(f"  å›¾åƒå°ºå¯¸: {blip_config.model.image_size}")
        
        # éªŒè¯é…ç½®å·®å¼‚
        assert clip_config.model.name != blip_config.model.name
        assert clip_config.model.image_size != blip_config.model.image_size
        
        print("âœ“ æ¨¡å‹é…ç½®æ¯”è¾ƒé€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹æ¯”è¾ƒæµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("æ¨¡å‹é›†æˆæµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("é…ç½®ç³»ç»Ÿ", test_config_system),
        ("æ¨¡å‹å¯¼å…¥", test_model_imports),
        ("æ¨¡å‹åˆ›å»º", test_model_creation),
        ("ä¸»ç¨‹åºå‚æ•°", test_main_arguments),
        ("æ¨¡å‹æ¯”è¾ƒ", test_model_comparison)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{test_name}æµ‹è¯•:")
        print("-" * 30)
        if test_func():
            passed += 1
            print(f"âœ“ {test_name}æµ‹è¯•é€šè¿‡")
        else:
            print(f"âœ— {test_name}æµ‹è¯•å¤±è´¥")
    
    print(f"\næµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼BLIPé›†æˆæˆåŠŸã€‚")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  python main.py --model CLIP    # ä½¿ç”¨CLIPæ¨¡å‹")
        print("  python main.py --model BLIP    # ä½¿ç”¨BLIPæ¨¡å‹")
        print("  python main.py --list-models   # åˆ—å‡ºæ”¯æŒçš„æ¨¡å‹")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é›†æˆã€‚")

if __name__ == "__main__":
    main()
